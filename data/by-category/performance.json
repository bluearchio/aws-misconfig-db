{
  "category": "performance",
  "count": 29,
  "misconfigurations": [
    {
      "id": "444fd30a-f2f2-4a7f-afbc-063349fc900f",
      "status": "open",
      "service_name": "ebs",
      "scenario": "Amazon EBS Provisioned IOPS (SSD) Volume Attachment Configuration",
      "alert_criteria": "An Amazon EC2 instance that can be EBS-optimized has an attached Provisioned IOPS (SSD) volume but the instance is not EBS-optimized.",
      "recommendation_action": "create new \"ebs-optimized\" ssd by provisioning a new instance",
      "risk_detail": "performance",
      "build_priority": 0,
      "action_value": 1,
      "effort_level": 1,
      "risk_value": 1,
      "recommendation_description_detailed": "Checks for Provisioned IOPS (SSD) volumes that are attached to an Amazon EBS-optimizable Amazon Elastic Compute Cloud (Amazon EC2) instance that is not EBS-optimized. Provisioned IOPS (SSD) volumes in the Amazon Elastic Block Store (Amazon EBS) are designed to deliver the expected performance only when they are attached to an EBS-optimized instance.",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html",
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-attaching-volume.html"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "03060d2d-96d3-43aa-ba18-2968fc8a7189",
      "status": "open",
      "service_name": "ebs",
      "scenario": "Overutilized Amazon EBS Magnetic Volumes",
      "alert_criteria": "An Amazon EBS Magnetic volume is attached to an instance that can be EBS-optimized or is part of a cluster compute network with a daily median of more than 95 IOPS, and varies by less than 10% of the median value for at least 7 of the past 14 days.",
      "recommendation_action": "- For consistently higher IOPS, you can use a Provisioned IOPS (SSD) volume. \n- For bursty IOPS, you can use a General Purpose (SSD) volume",
      "risk_detail": "performance",
      "build_priority": 0,
      "action_value": 2,
      "effort_level": 1,
      "risk_value": 1,
      "recommendation_description_detailed": "Checks for Amazon Elastic Block Store (EBS) Magnetic volumes that are potentially overutilized and might benefit from a more efficient configuration. A Magnetic volume is designed for applications with moderate or bursty I/O requirements, and the IOPS rate is not guaranteed. It delivers approximately 100 IOPS on average, with a best-effort ability to burst to hundreds of IOPS. For consistently higher IOPS, you can use a Provisioned IOPS (SSD) volume. For bursty IOPS, you can use a General Purpose (SSD) volume. To get daily utilization metrics, download the report for this check. The detailed report shows a column for each of the last 14 days. If there is no active EBS volume, the cell is empty. If there is  insufficient data to make a reliable measurement, the cell contains \"N/A\". If there is sufficient data, the cell contains the daily median and the percentage of the variance in relation to the median (for example, \"256 / 20%\").",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "3bcb0076-e857-4761-988a-4982185813a5",
      "status": "open",
      "service_name": "ec2",
      "scenario": "ec2 network performance is not what is expected / paid for",
      "alert_criteria": "using aws inventory stats, compare actual performance to that of expected...",
      "recommendation_action": "upgrade to a modern ec2 instance type with guaranteed network performance; co-locate all ec2s",
      "risk_detail": "performance",
      "build_priority": 3,
      "action_value": 2,
      "effort_level": 3,
      "risk_value": 1,
      "recommendation_description_detailed": "\"noisy neighbors\" are stealing network I/O performance",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html",
        "https://www.quora.com/How-did-you-fix-the-noisy-neighbor-problem-while-using-Amazon-EC2"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "8dcdbfff-850b-40c9-96c7-3186a9fe04ea",
      "status": "open",
      "service_name": "ec2",
      "scenario": "Amazon EC2 to EBS Throughput Optimization",
      "alert_criteria": "Compare the maximum throughput of your EBS volumes (see Amazon EBS Volume Types) with the maximum throughput of the EC2 instance they are attached to (see Instance Types That Support EBS Optimization). Consider attaching your volumes to an instance that supports higher throughput to EBS for optimal performance.; In the preceding day (UTC), the aggregate throughput (megabytes/sec) of the EBS volumes attached to the EC2 instance exceeded 95% of the published throughput between the instance and the EBS volumes more than 50% of time.",
      "recommendation_action": "Compare the maximum throughput of your EBS volumes (see Amazon EBS Volume Types) with the maximum throughput of the EC2 instance they are attached to (see Instance Types That Support EBS Optimization). Consider attaching your volumes to an instance that supports higher throughput to EBS for optimal performance.",
      "risk_detail": "performance",
      "build_priority": 0,
      "action_value": 1,
      "effort_level": 1,
      "risk_value": 1,
      "recommendation_description_detailed": "Checks for Amazon EBS volumes whose performance might be affected by the maximum throughput capability of the Amazon EC2 instance they are attached to. To optimize performance, you should ensure that the maximum throughput of an EC2 instance is greater than the aggregate maximum throughput of the attached EBS volumes. This check computes the total EBS volume throughput for each five-minute period in the preceding day (UTC) for each EBS-optimized instance and alerts you if usage in more than half of those periods was greater than 95% of the maximum throughput of the EC2 instance",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html#ebs-optimization-support",
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using_cloudwatch_ebs.html",
        "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "f15adfc7-d970-4925-b0fb-99dbe1796d3b",
      "status": "open",
      "service_name": "ec2",
      "scenario": "High Utilization Amazon EC2 Instances",
      "alert_criteria": "An instance had more than 90% daily average CPU utilization on at least 4 of the previous 14 days.",
      "recommendation_action": "- add more instanes OR increase instance size\n- add ALB to application",
      "risk_detail": "performance",
      "build_priority": 0,
      "action_value": 2,
      "effort_level": 2,
      "risk_value": 1,
      "recommendation_description_detailed": "Checks the Amazon Elastic Compute Cloud (Amazon EC2) instances that were running at any time during the last 14 days and alerts you if the daily CPU utilization was more than 90% on 4 or more days. Consistent high utilization can indicate optimized, steady performance, but it can also indicate that an application does not have enough resources. To get daily CPU utilization data, download the report for this check",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "863e1006-a446-4efb-99d3-b6408c851cd0",
      "status": "open",
      "service_name": "ec2",
      "scenario": "Production workloads without Auto Scaling unable to optimize costs during variable demand",
      "alert_criteria": "EC2 workloads with variable traffic patterns running fixed capacity without Auto Scaling, or Auto Scaling groups using only simple scaling without target tracking",
      "recommendation_action": "Configure AWS Auto Scaling with target tracking policies for CPU/memory, implement predictive scaling for known patterns, and use scheduled scaling for recurring events",
      "risk_detail": "cost, performance",
      "build_priority": 2,
      "action_value": 3,
      "effort_level": 2,
      "risk_value": 2,
      "recommendation_description_detailed": "COST09-BP03: Auto Scaling ensures you only pay for needed capacity while maintaining performance. Use target tracking for automatic scaling based on metrics (e.g., CPU 50%), predictive scaling for traffic patterns (pre-scaling before daily spikes), and scheduled scaling for known events. Combine with mixed instance types (On-Demand + Spot) for additional savings. Implement across EC2, ECS, DynamoDB, and Aurora. Properly configured Auto Scaling reduces costs by 20-40% while improving availability.",
      "category": "cost",
      "output_notes": null,
      "notes": "AWS Well-Architected Framework COST09-BP03 - Auto Scaling is fundamental to cloud cost optimization",
      "references": [
        "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_manage_demand_resources_dynamic.html",
        "https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html"
      ],
      "metadata": {
        "created_at": "2025-11-06T05:13:46.581727+00:00",
        "updated_at": "2025-11-06T05:13:46.581727+00:00",
        "contributors": [
          "aws-well-architected-2025"
        ],
        "source": "AWS Well-Architected Framework Cost Optimization Pillar 2025"
      },
      "tags": [
        "auto-scaling",
        "target-tracking",
        "predictive-scaling",
        "dynamic-capacity"
      ]
    },
    {
      "id": "5fc3d4a9-96ef-4bba-82e9-bccabe531b34",
      "status": "open",
      "service_name": "eks",
      "scenario": "pods OR nodes within cluster are not appropriately sized (artur to clarify)",
      "alert_criteria": "workloads (cpu, memory, network IOPs, etc.) for the previous 14, 30, 90 days, multiplied by 1.4 are too large...",
      "recommendation_action": "recommend the proper size for each pod",
      "risk_detail": "cost, performance",
      "build_priority": null,
      "action_value": null,
      "effort_level": null,
      "risk_value": null,
      "recommendation_description_detailed": "",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "2b6ae2c7-d432-401b-8164-23782cb1b1dc",
      "status": "open",
      "service_name": "emr",
      "scenario": "EMR (or other) cluster is used and task nodes are not utilizing spot instances",
      "alert_criteria": "",
      "recommendation_action": "use spot instances",
      "risk_detail": "performance, cost",
      "build_priority": 1,
      "action_value": 3,
      "effort_level": 2,
      "risk_value": 2,
      "recommendation_description_detailed": "useful for high CPU but low Memory requirements; i.e. high processing requirement but low (or no) caching required",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "b3c7e2d1-8a4f-4b6e-9c5d-7e1a8f3b2c4d",
      "status": "open",
      "service_name": "rds",
      "scenario": "RDS instances using GP2 storage instead of cost-effective GP3 storage type",
      "alert_criteria": "RDS instances with gp2 storage type, especially those with low IOPS requirements (<3000 IOPS)",
      "recommendation_action": "Migrate RDS storage from GP2 to GP3 for 20% cost savings with same or better performance, using AWS console or modify-db-instance CLI command",
      "risk_detail": "cost, performance",
      "build_priority": 2,
      "action_value": 3,
      "effort_level": 1,
      "risk_value": 1,
      "recommendation_description_detailed": "GP3 storage offers 20% lower cost than GP2 with better baseline performance (3000 IOPS and 125 MB/s regardless of size vs GP2 performance scaling with size). GP3 pricing: $0.08/GB-month vs GP2 $0.10/GB-month. Migration is online with no downtime for most engines. GP3 allows independent IOPS and throughput provisioning (cost-effective for workloads needing high throughput but not high IOPS). Best candidates: databases >100GB where GP2 over-provisions performance. Calculate savings: (current_storage_GB * $0.02) * 12 months.",
      "category": "cost",
      "output_notes": null,
      "notes": "AWS Well-Architected Framework COST05 - GP3 is newer, faster, and 20% cheaper than GP2",
      "references": [
        "https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html",
        "https://aws.amazon.com/rds/features/storage/"
      ],
      "metadata": {
        "created_at": "2025-11-06T17:41:02.278720+00:00",
        "updated_at": "2025-11-06T17:41:02.278720+00:00",
        "contributors": [
          "aws-well-architected-2025"
        ],
        "source": "AWS Well-Architected Framework Cost Optimization Pillar 2025"
      },
      "tags": [
        "rds-storage",
        "gp3",
        "gp2-migration",
        "storage-type-optimization"
      ]
    },
    {
      "id": "b2c3d4e5-f6a7-4890-b123-456789abcdef",
      "status": "open",
      "service_name": "rds",
      "scenario": "Database queries repeated without caching layer implementation",
      "alert_criteria": "RDS DatabaseConnections >80% of max, identical SELECT queries >1000/min, or query response time >100ms for cacheable data",
      "recommendation_action": "Implement Cache-Aside pattern: 1) Deploy ElastiCache Redis/Memcached cluster, 2) Modify application to check cache before database, 3) Set appropriate TTL (5min for product catalog, 1hr for reference data), 4) Monitor cache hit rate (target >80%)",
      "risk_detail": "performance, cost, reliability",
      "build_priority": 1,
      "action_value": 3,
      "effort_level": 2,
      "risk_value": 2,
      "recommendation_description_detailed": "Cache-Aside pattern reduces database load by 70-95% for read-heavy workloads. Application checks cache first; on miss, queries database and populates cache. Without caching: 10,000 reads/sec on RDS = $500/month + performance degradation. With ElastiCache: cache.r6g.large = $175/month + 95% cache hit rate = $200 total vs $500 (60% savings). Additional benefits: reduced RDS instance size, improved response time (1ms cache vs 50ms database). Critical for: product catalogs, user profiles, reference data, API responses.",
      "category": "database",
      "architectural_patterns": [
        {
          "pattern_name": "Cache-Aside",
          "relationship": "missing_implementation",
          "description": "No caching layer between application and database for frequently accessed data"
        }
      ],
      "pattern_implementation_guidance": "Create ElastiCache Redis cluster (Multi-AZ for production), update application connection string, implement cache access pattern: GET from cache -> if miss -> GET from DB -> SET in cache with TTL, use consistent cache key format (service:entity:id), handle cache failures gracefully (fallback to DB), set CloudWatch alarms for cache hit rate <70%.",
      "output_notes": null,
      "notes": "AWS Database Caching Strategies - Cache-Aside Pattern",
      "references": [
        "https://docs.aws.amazon.com/whitepapers/latest/database-caching-strategies-using-redis/caching-patterns.html",
        "https://aws.amazon.com/caching/best-practices/",
        "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Strategies.html"
      ],
      "metadata": {
        "created_at": "2025-11-06T20:44:23.794745+00:00",
        "updated_at": "2025-11-06T20:44:23.794745+00:00",
        "contributors": [
          "pattern-integration-2025"
        ],
        "source": "AWS Database Caching Strategies - Cache-Aside Pattern"
      },
      "tags": [
        "pattern:cache-aside",
        "performance-pattern",
        "elasticache",
        "database-optimization",
        "read-heavy-workload"
      ],
      "detection_methods": [
        {
          "method": "RDS Performance Insights",
          "details": "Top SQL queries showing identical SELECT statements with >1000 executions/minute"
        }
      ],
      "remediation_examples": [
        {
          "language": "python",
          "code": "import boto3\nimport json\nfrom redis import Redis\n\nredis_client = Redis(host='elasticache-endpoint', port=6379)\n\ndef get_user_profile(user_id):\n    cache_key = f'user:profile:{user_id}'\n    cached = redis_client.get(cache_key)\n    if cached:\n        return json.loads(cached)\n    \n    # Cache miss - query database\n    result = query_database(user_id)\n    redis_client.setex(cache_key, 300, json.dumps(result))  # 5-min TTL\n    return result",
          "description": "Python implementation of Cache-Aside with ElastiCache Redis and RDS"
        }
      ]
    },
    {
      "id": "e39158bd-8550-4a6e-ba9f-6060f584ec73",
      "status": "ice",
      "service_name": "route 53",
      "scenario": "Amazon Route 53 Alias Resource Record Sets",
      "alert_criteria": "A resource record set is a CNAME to an Amazon CloudFront distribution.",
      "recommendation_action": "Replace the listed CNAME resource record sets with alias resource record sets; You also need to change the record type from CNAME to A or AAAA, depending on the AWS resource",
      "risk_detail": "performance",
      "build_priority": null,
      "action_value": null,
      "effort_level": null,
      "risk_value": null,
      "recommendation_description_detailed": "Checks for resource record sets that can be changed to alias resource record sets to improve performance and save money. An alias resource record set routes DNS queries to an AWS resource (for example, an Elastic Load Balancing load balancer or an Amazon S3 bucket) or to another Route 53 resource record set. When you use alias resource record sets, Route 53 routes your DNS queries to AWS resources free of charge. Hosted zones created by AWS services won’t appear in your check results.",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html",
        "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-values.html"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "c5a5b3c1-b229-4839-8c91-63c630ad1fb9",
      "status": "ice",
      "service_name": "route 53",
      "scenario": "Amazon Route 53 Alias Resource Record Sets",
      "alert_criteria": "A resource record set is a CNAME to an Elastic Load Balancing load balancer.",
      "recommendation_action": "Replace the listed CNAME resource record sets with alias resource record sets; You also need to change the record type from CNAME to A or AAAA, depending on the AWS resource",
      "risk_detail": "performance",
      "build_priority": null,
      "action_value": null,
      "effort_level": null,
      "risk_value": null,
      "recommendation_description_detailed": "Checks for resource record sets that can be changed to alias resource record sets to improve performance and save money. An alias resource record set routes DNS queries to an AWS resource (for example, an Elastic Load Balancing load balancer or an Amazon S3 bucket) or to another Route 53 resource record set. When you use alias resource record sets, Route 53 routes your DNS queries to AWS resources free of charge. Hosted zones created by AWS services won’t appear in your check results.",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html",
        "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-values.html"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "81a5a270-6eef-45f9-921b-593eb7ef6bd6",
      "status": "open",
      "service_name": "lambda",
      "scenario": "time between when the last record in a batch was written to a stream (e.g., Kinesis, DynamoDB) and when Lambda received the batch increases dramatically",
      "alert_criteria": "",
      "recommendation_action": "",
      "risk_detail": "performance",
      "build_priority": 3,
      "action_value": null,
      "effort_level": null,
      "risk_value": null,
      "recommendation_description_detailed": "There are a few scenarios that could increase the iterator age:\n    a high execution duration for a function\n    not enough shards in a stream\n    invocation errors\n    insufficient batch size",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "14e59ac7-8087-4489-8073-4bee498c0897",
      "status": "open",
      "service_name": "lambda",
      "scenario": "user wants to limit the time it takes to load and initialize function calls (as the current initialization code runtime takes too long)",
      "alert_criteria": "**requires x-ray to be enabled**\naverage and percentile of initialization latency is above threshold",
      "recommendation_action": "provision resserved capacity to reduce cold-start time",
      "risk_detail": "performance",
      "build_priority": 2,
      "action_value": 2,
      "effort_level": 2,
      "risk_value": 0,
      "recommendation_description_detailed": "",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "c8fd0f3c-90c1-45ec-9467-963920497527",
      "status": "open",
      "service_name": "lambda",
      "scenario": "use wants to be made aware of any function throttling that ocurrs",
      "alert_criteria": "function throttle counts are above threshold",
      "recommendation_action": "- place limits on how many concurrent \"slices\" (percentage of total concurrency available to your account / region) a single function can have\n- request unreserved (5000) concurrency limit increases (no cost)\n- configure a dlq to capture failure(s)",
      "risk_detail": "performance, operations",
      "build_priority": 2,
      "action_value": 2,
      "effort_level": 2,
      "risk_value": 3,
      "recommendation_description_detailed": "",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://aws.amazon.com/premiumsupport/knowledge-center/lambda-troubleshoot-throttling/"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "1d169e83-e553-4a67-8796-1c4365265efc",
      "status": "open",
      "service_name": "lambda",
      "scenario": "user wants to avoide lambda function throttling",
      "alert_criteria": "concurrent executions in a period of time are predicted to exceed to concurrent execution limits (account limit -100)",
      "recommendation_action": "- place limits on how many concurrent \"slices\" (percentage of total concurrency available to your account / region) a single function can have\n- request unreserved (5000) concurrency limit increases (no cost)\n- configure a dlq to capture failure(s)",
      "risk_detail": "performance, operations",
      "build_priority": 2,
      "action_value": 3,
      "effort_level": 2,
      "risk_value": 1,
      "recommendation_description_detailed": "",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "44183041-c87c-4bf2-ab10-3a593057135a",
      "status": "open",
      "service_name": "lambda",
      "scenario": "lambda function consistently and significantly under memory limits",
      "alert_criteria": "lambda functions' average memory used is less than threshold in time period",
      "recommendation_action": "decrease lambda function memory",
      "risk_detail": "performance",
      "build_priority": 1,
      "action_value": 2,
      "effort_level": 1,
      "risk_value": 2,
      "recommendation_description_detailed": "",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-supports-10gb-memory-6-vcpu-cores-lambda-functions/"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "f11f43fb-072f-4a2a-9a4a-2851f8bae0aa",
      "status": "open",
      "service_name": "lambda",
      "scenario": "lambda function consistently reaches memory limits",
      "alert_criteria": "average percent use of concurrency pool is greater than threshold and lambda functions' average memory used is greater than threshold in time period",
      "recommendation_action": "increase lambda function memory",
      "risk_detail": "performance",
      "build_priority": 1,
      "action_value": 2,
      "effort_level": 1,
      "risk_value": 2,
      "recommendation_description_detailed": "",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-supports-10gb-memory-6-vcpu-cores-lambda-functions/"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "a1b2c3d4-e5f6-4789-a012-3456789abcde",
      "status": "open",
      "service_name": "lambda",
      "scenario": "Lambda functions making synchronous calls to external services without circuit breaker implementation",
      "alert_criteria": "Lambda functions with >20% timeout errors when calling downstream services, or Lambda functions with synchronous external API calls without fault tolerance",
      "recommendation_action": "Implement circuit breaker pattern: 1) Use Step Functions with error handling, 2) Add circuit breaker logic in Lambda using ElastiCache/DynamoDB for state, 3) Configure Lambda reserved concurrency to prevent cascade failures",
      "risk_detail": "reliability, performance, cost",
      "build_priority": 1,
      "action_value": 3,
      "effort_level": 2,
      "risk_value": 3,
      "recommendation_description_detailed": "Without circuit breaker pattern, Lambda functions repeatedly attempt to call unavailable downstream services, causing cascading failures and wasted costs. Circuit breaker detects failure threshold (e.g., 50% errors in 10 attempts), opens circuit to fail fast for 30 seconds, then half-opens to test recovery. AWS implementation: Lambda + DynamoDB for state tracking, or AWS Resilience Hub. Cost impact: Without circuit breaker, failed calls waste execution time; with fast-fail pattern, costs reduced by 80-90% during downstream outages.",
      "category": "compute",
      "architectural_patterns": [
        {
          "pattern_name": "Circuit Breaker",
          "relationship": "missing_implementation",
          "description": "No circuit breaker logic to prevent repeated calls to failing downstream services"
        }
      ],
      "pattern_implementation_guidance": "Implement using: 1) Lambda Layer with circuit breaker library (pybreaker for Python, opossum for Node.js), 2) DynamoDB table to store circuit state (service_name, failure_count, circuit_state, last_failure_time), 3) Lambda environment variables for thresholds (failure_threshold=5, timeout=30s), 4) CloudWatch alarms when circuit opens. Example: pybreaker library with @breaker decorator.",
      "output_notes": null,
      "notes": "AWS Prescriptive Guidance - Circuit Breaker Pattern",
      "references": [
        "https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/circuit-breaker.html",
        "https://aws.amazon.com/builders-library/timeouts-retries-and-backoff-with-jitter/",
        "https://docs.aws.amazon.com/resilience-hub/latest/userguide/what-is.html"
      ],
      "metadata": {
        "created_at": "2025-11-06T20:44:23.794745+00:00",
        "updated_at": "2025-11-06T20:44:23.794745+00:00",
        "contributors": [
          "pattern-integration-2025"
        ],
        "source": "AWS Prescriptive Guidance - Circuit Breaker Pattern"
      },
      "tags": [
        "pattern:circuit-breaker",
        "resilience-pattern",
        "fault-tolerance",
        "cascade-failure-prevention"
      ],
      "detection_methods": [
        {
          "method": "CloudWatch Metric",
          "details": "Lambda Errors metric > 20% for functions with external dependencies"
        }
      ],
      "remediation_examples": [
        {
          "language": "python",
          "code": "from pybreaker import CircuitBreaker\nbreaker = CircuitBreaker(fail_max=5, timeout_duration=30)\n\n@breaker\ndef call_external_service():\n    response = requests.get('https://api.example.com/data')\n    return response.json()\n\ndef lambda_handler(event, context):\n    try:\n        data = call_external_service()\n        return {'statusCode': 200, 'body': data}\n    except CircuitBreakerError:\n        return {'statusCode': 503, 'body': 'Service temporarily unavailable'}",
          "description": "Python Lambda with pybreaker library - 5 failure threshold, 30-second timeout"
        }
      ]
    },
    {
      "id": "c3d4e5f6-a7b8-4901-c234-56789abcdef0",
      "status": "open",
      "service_name": "lambda",
      "scenario": "Lambda functions making external API calls without retry logic or using fixed-interval retries",
      "alert_criteria": "Lambda functions with throttling errors from external APIs (429 responses), timeout errors >5%, or no SDK retry configuration",
      "recommendation_action": "Implement Retry with Exponential Backoff: 1) Use AWS SDK built-in retry (Standard mode: 3 attempts, exponential backoff), 2) Add jitter to prevent thundering herd, 3) Configure Lambda reserved concurrency, 4) Use Step Functions for complex retry scenarios",
      "risk_detail": "reliability, cost, performance",
      "build_priority": 1,
      "action_value": 3,
      "effort_level": 1,
      "risk_value": 2,
      "recommendation_description_detailed": "Fixed-interval retries or no retries waste Lambda execution time and potentially overwhelm recovering services. Exponential backoff: 1st retry after 1s, 2nd after 2s, 3rd after 4s (with jitter ±50%). AWS SDK default provides 3 retries with exponential backoff. Most transient failures (network timeouts, 429/503 errors) succeed on retry. Without retry: 10% transient failures = 100K errors per 1M invocations. With backoff retry: 95K recovered, 5K permanent failures, costs minimal extra execution time vs massive improvement in reliability.",
      "category": "compute",
      "architectural_patterns": [
        {
          "pattern_name": "Retry with Exponential Backoff",
          "relationship": "missing_implementation",
          "description": "No retry logic or fixed-interval retries causing thundering herd and service degradation"
        }
      ],
      "pattern_implementation_guidance": "Configure AWS SDK retry mode in Lambda environment variables: AWS_RETRY_MODE=standard, AWS_MAX_ATTEMPTS=3. For custom retries: implement exponential backoff with jitter (delay = min(max_delay, base_delay * 2^attempt * random(0.5, 1.5))). Only retry transient errors (429, 500, 502, 503, 504, timeouts). For Step Functions: use Retry field with BackoffRate=2.0, MaxAttempts=3.",
      "output_notes": null,
      "notes": "AWS Builders Library - Timeouts, Retries, and Backoff with Jitter",
      "references": [
        "https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/retry-backoff.html",
        "https://aws.amazon.com/builders-library/timeouts-retries-and-backoff-with-jitter/",
        "https://docs.aws.amazon.com/general/latest/gr/api-retries.html"
      ],
      "metadata": {
        "created_at": "2025-11-06T20:44:23.794745+00:00",
        "updated_at": "2025-11-06T20:44:23.794745+00:00",
        "contributors": [
          "pattern-integration-2025"
        ],
        "source": "AWS Prescriptive Guidance - Retry with Backoff Pattern"
      },
      "tags": [
        "pattern:retry-backoff",
        "resilience-pattern",
        "transient-error-handling",
        "api-integration"
      ],
      "detection_methods": [
        {
          "method": "CloudWatch Logs Insights",
          "details": "Query Lambda logs for HTTP 429/503 responses or timeout errors"
        }
      ],
      "remediation_examples": [
        {
          "language": "python",
          "code": "from botocore.config import Config\nimport boto3\n\n# Configure AWS SDK with retry\nconfig = Config(retries={'mode': 'adaptive', 'max_attempts': 5})\ndynamodb = boto3.client('dynamodb', config=config)",
          "description": "Python Lambda with AWS SDK adaptive retry configuration"
        }
      ]
    },
    {
      "id": "d4e5f6a7-b8c9-4012-d345-6789abcdef01",
      "status": "open",
      "service_name": "lambda",
      "scenario": "Lambda functions processing variable workload spikes synchronously without message queue buffering",
      "alert_criteria": "Lambda throttling errors >100/hour, API Gateway 5xx errors during traffic spikes, or direct synchronous invocation of compute-intensive functions",
      "recommendation_action": "Implement Queue-Based Load Leveling: 1) Place SQS queue between API Gateway and Lambda, 2) Configure API Gateway to send messages to SQS, 3) Set Lambda as SQS consumer with batch size 10-100, 4) Configure DLQ for failed messages, 5) Monitor queue depth",
      "risk_detail": "reliability, performance, cost",
      "build_priority": 1,
      "action_value": 3,
      "effort_level": 2,
      "risk_value": 2,
      "recommendation_description_detailed": "Synchronous processing fails during traffic spikes (10x spike = 90% failures). Queue-Based Load Leveling decouples request acceptance from processing: API Gateway succeeds immediately (200 OK after SQS write), Lambda processes at sustainable rate. Benefits: 1) No lost requests during spikes, 2) Consistent processing rate, 3) Auto-scaling based on queue depth. Example: E-commerce flash sale - 10K requests/sec spike vs 1K/sec capacity. Without queue: 9K failures. With SQS: all accepted, processed within SLA. Cost: SQS = $0.40 per million requests.",
      "category": "messaging",
      "architectural_patterns": [
        {
          "pattern_name": "Queue-Based Load Leveling",
          "relationship": "missing_implementation",
          "description": "Direct synchronous processing without queue buffer for variable workloads"
        }
      ],
      "pattern_implementation_guidance": "Create SQS queue (Standard for throughput, FIFO for ordering), create DLQ, update API Gateway integration to SQS (Action=SendMessage), create Lambda trigger from SQS with BatchSize=10, set Lambda reserved concurrency to control rate, configure CloudWatch alarms: ApproximateAgeOfOldestMessage >300s.",
      "output_notes": null,
      "notes": "AWS Architecture - Queue-Based Load Leveling Pattern",
      "references": [
        "https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html",
        "https://aws.amazon.com/blogs/compute/understanding-how-aws-lambda-scales-with-amazon-sqs-standard-queues/",
        "https://docs.aws.amazon.com/apigateway/latest/developerguide/integrating-api-with-aws-services-sqs.html"
      ],
      "metadata": {
        "created_at": "2025-11-06T20:44:23.794745+00:00",
        "updated_at": "2025-11-06T20:44:23.794745+00:00",
        "contributors": [
          "pattern-integration-2025"
        ],
        "source": "AWS Architecture - Queue-Based Load Leveling Pattern"
      },
      "tags": [
        "pattern:queue-load-leveling",
        "resilience-pattern",
        "sqs",
        "traffic-spike-handling",
        "decoupling"
      ]
    },
    {
      "id": "e5f6a7b8-c9d0-4123-e456-789abcdef012",
      "status": "open",
      "service_name": "lambda",
      "scenario": "Multiple Lambda functions sharing unreserved concurrency pool without isolation",
      "alert_criteria": "Account-level Lambda throttling, critical functions throttled due to non-critical functions consuming concurrency, or no reserved concurrency configured for production workloads",
      "recommendation_action": "Implement Bulkhead pattern: 1) Allocate reserved concurrency to critical functions (payment=200, auth=150), 2) Leave unreserved pool for non-critical, 3) Monitor per-function concurrency, 4) Use Application Auto Scaling for dynamic adjustment",
      "risk_detail": "reliability, operations, performance",
      "build_priority": 1,
      "action_value": 3,
      "effort_level": 1,
      "risk_value": 3,
      "recommendation_description_detailed": "Bulkhead pattern prevents single function from exhausting shared concurrency pool (default 1000 per account). Without bulkheads: batch job consuming 900 executions throttles payment processing (revenue loss). With reserved concurrency: payment=200 reserved, batch=100 reserved, 700 unreserved. If batch spikes, only impacts unreserved pool. Reserved concurrency is FREE, only pay for actual executions. Critical for: multi-tenant systems, mixed criticality workloads, production+development in same account.",
      "category": "compute",
      "architectural_patterns": [
        {
          "pattern_name": "Bulkhead",
          "relationship": "missing_implementation",
          "description": "No isolation between Lambda functions using shared concurrency pool"
        }
      ],
      "pattern_implementation_guidance": "Identify critical vs non-critical functions, calculate required concurrency (avg * 1.5 + buffer), set reserved concurrency: aws lambda put-function-concurrency --function-name critical-api --reserved-concurrent-executions 200, monitor ConcurrentExecutions metric, set CloudWatch alarms when usage >80% of reserved.",
      "output_notes": null,
      "notes": "AWS Well-Architected Framework - Bulkhead Pattern for Resource Isolation",
      "references": [
        "https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html",
        "https://aws.amazon.com/blogs/compute/managing-aws-lambda-function-concurrency/"
      ],
      "metadata": {
        "created_at": "2025-11-06T20:44:23.794745+00:00",
        "updated_at": "2025-11-06T20:44:23.794745+00:00",
        "contributors": [
          "pattern-integration-2025"
        ],
        "source": "AWS Well-Architected Framework - Bulkhead Pattern"
      },
      "tags": [
        "pattern:bulkhead",
        "resilience-pattern",
        "lambda-concurrency",
        "resource-isolation",
        "noisy-neighbor"
      ],
      "remediation_examples": [
        {
          "language": "aws-cli",
          "code": "aws lambda put-function-concurrency --function-name payment-processing --reserved-concurrent-executions 200",
          "description": "Set reserved concurrency for critical function isolation"
        }
      ]
    },
    {
      "id": "937fff55-6361-4546-a3be-9b4769c904e4",
      "status": "open",
      "service_name": "cloudfront",
      "scenario": "CloudFront Header Forwarding and Cache Hit Ratio",
      "alert_criteria": "One or more request headers that CloudFront forwards to your origin might significantly reduce your cache hit ratio.",
      "recommendation_action": "Consider whether the request headers provide enough benefit to justify the negative effect on the cache hit ratio. If your origin returns the same object regardless of the value of a given header, we recommend that you don't configure CloudFront to forward that header to the origin.",
      "risk_detail": "performance",
      "build_priority": 2,
      "action_value": null,
      "effort_level": null,
      "risk_value": null,
      "recommendation_description_detailed": "Checks the HTTP request headers that CloudFront currently receives from the client and forwards to your origin server. Some headers, such as Date or User-Agent, significantly reduce the cache hit ratio (the proportion of requests that are served from a CloudFront edge cache). This increases the load on your origin and reduces performance because CloudFront must forward more requests to your origin",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/header-caching.html"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "915cc2d1-9ea7-4fab-83ad-92b623cb163b",
      "status": "open",
      "service_name": "cloudfront",
      "scenario": "CloudFront Alternate Domain Names",
      "alert_criteria": "Yellow: A CloudFront distribution includes alternate domain names, but the DNS configuration is not correctly set up with a CNAME record or an Amazon Route 53 alias resource record.",
      "recommendation_action": "Update the DNS configuration to route DNS queries to the CloudFront distribution",
      "risk_detail": "performance",
      "build_priority": 1,
      "action_value": null,
      "effort_level": null,
      "risk_value": null,
      "recommendation_description_detailed": "Checks Amazon CloudFront distributions for alternate domain names (CNAMES) that have incorrectly configured DNS settings. If a CloudFront distribution includes alternate domain names, the DNS configuration for the domains must route DNS queries to that distribution.\n\nNote: This check assumes Amazon Route 53 DNS and Amazon CloudFront distribution are configured in the same AWS account. As such the Alert list may include resources otherwise working as expected due to DNS setting outsides of this AWS account.",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/CNAMEs.html",
        "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-cloudfront-distribution.html"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "4769bb75-f7b8-4604-8ad1-2fbdabd7420d",
      "status": "open",
      "service_name": "cloudfront",
      "scenario": "CloudFront Content Delivery Optimization",
      "alert_criteria": "The amount of data transferred out of the bucket to your users by GET requests in the 30 days preceding the check is at least 25 times greater than the average amount of data stored in the bucket.",
      "recommendation_action": "Consider using CloudFront for better performance",
      "risk_detail": "performance",
      "build_priority": 0,
      "action_value": null,
      "effort_level": null,
      "risk_value": null,
      "recommendation_description_detailed": "Checks for cases where data transfer from Amazon Simple Storage Service (Amazon S3) buckets could be accelerated by using Amazon CloudFront, the AWS global content delivery service. When you configure CloudFront to deliver your content, requests for your content are automatically routed to the nearest edge location where content is cached, so it can be delivered to your users with the best possible performance. A high ratio of data transferred out to the data stored in the bucket indicates that you could benefit from using Amazon CloudFront to deliver the data. To estimate the retrieval activity of users, only data transferred by using a GET request is counted for this check. In addition, the transfer activity from the last 24 hours is not included.",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://aws.amazon.com/cloudfront/features/",
        "https://aws.amazon.com/cloudfront/pricing/"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "cc4250bc-4065-4a12-8fa8-74f386b45702",
      "status": "open",
      "service_name": "cloudfront",
      "scenario": "CloudFront Content Delivery Optimization",
      "alert_criteria": "The amount of data transferred out of the bucket to your users by GET requests in the 30 days preceding the check is at least 10 TB and at least 25 times greater than the average amount of data stored in the bucket.",
      "recommendation_action": "If the data transferred is 10 TB per month or more, see Amazon CloudFront Pricing to explore possible cost savings.",
      "risk_detail": "performance",
      "build_priority": 0,
      "action_value": null,
      "effort_level": null,
      "risk_value": null,
      "recommendation_description_detailed": "Checks for cases where data transfer from Amazon Simple Storage Service (Amazon S3) buckets could be accelerated by using Amazon CloudFront, the AWS global content delivery service. When you configure CloudFront to deliver your content, requests for your content are automatically routed to the nearest edge location where content is cached, so it can be delivered to your users with the best possible performance. A high ratio of data transferred out to the data stored in the bucket indicates that you could benefit from using Amazon CloudFront to deliver the data. To estimate the retrieval activity of users, only data transferred by using a GET request is counted for this check. In addition, the transfer activity from the last 24 hours is not included.",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://aws.amazon.com/cloudfront/features/",
        "https://aws.amazon.com/cloudfront/pricing/"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "ef6b202e-cb88-4f1b-aadb-a2f17804a8e5",
      "status": "open",
      "service_name": "cloudfront",
      "scenario": "CloudFront Alternate Domain Names",
      "alert_criteria": "Yellow: A CloudFront distribution includes alternate domain names, but Trusted Advisor could not evaluate the DNS configuration because there were too many redirects.",
      "recommendation_action": "Update the DNS configuration to route DNS queries to the CloudFront distribution",
      "risk_detail": "performance",
      "build_priority": null,
      "action_value": null,
      "effort_level": null,
      "risk_value": null,
      "recommendation_description_detailed": "Checks Amazon CloudFront distributions for alternate domain names (CNAMES) that have incorrectly configured DNS settings. If a CloudFront distribution includes alternate domain names, the DNS configuration for the domains must route DNS queries to that distribution.\n\nNote: This check assumes Amazon Route 53 DNS and Amazon CloudFront distribution are configured in the same AWS account. As such the Alert list may include resources otherwise working as expected due to DNS setting outsides of this AWS account.",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/CNAMEs.html",
        "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-cloudfront-distribution.html"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "0d84ee37-e841-4b16-ae87-5b0ec720c927",
      "status": "open",
      "service_name": "cloudfront",
      "scenario": "CloudFront Alternate Domain Names",
      "alert_criteria": "Yellow: A CloudFront distribution includes alternate domain names, but Trusted Advisor could not evaluate the DNS configuration for some other reason, most likely because of a timeout.",
      "recommendation_action": "Update the DNS configuration to route DNS queries to the CloudFront distribution",
      "risk_detail": "performance",
      "build_priority": null,
      "action_value": null,
      "effort_level": null,
      "risk_value": null,
      "recommendation_description_detailed": "Checks Amazon CloudFront distributions for alternate domain names (CNAMES) that have incorrectly configured DNS settings. If a CloudFront distribution includes alternate domain names, the DNS configuration for the domains must route DNS queries to that distribution.\n\nNote: This check assumes Amazon Route 53 DNS and Amazon CloudFront distribution are configured in the same AWS account. As such the Alert list may include resources otherwise working as expected due to DNS setting outsides of this AWS account.",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [
        "https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/CNAMEs.html",
        "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-cloudfront-distribution.html"
      ],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    },
    {
      "id": "15ac6ce0-cfab-4e25-87dd-ff769faec385",
      "status": "open",
      "service_name": "cloudfront",
      "scenario": "user wants their application optimized based on the command types (e,g, GET vs POST)",
      "alert_criteria": "",
      "recommendation_action": "",
      "risk_detail": "performance",
      "build_priority": null,
      "action_value": null,
      "effort_level": null,
      "risk_value": null,
      "recommendation_description_detailed": "command type (e.g. list vs get) have different pricing",
      "category": null,
      "output_notes": null,
      "notes": null,
      "references": [],
      "metadata": {
        "created_at": "2025-11-04T23:07:44.651478Z",
        "updated_at": "2025-11-04T23:07:44.651478Z",
        "contributors": [
          "initial-import"
        ],
        "source": "Initial CSV Import"
      },
      "tags": []
    }
  ]
}